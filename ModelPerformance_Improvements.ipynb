{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Dropout**"
      ],
      "metadata": {
        "id": "INLoK1m0qInP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of using dropout\n",
        "from sklearn.datasets import make_classification\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from matplotlib import pyplot\n",
        "# create the dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
        "# determine the number of input features\n",
        "n_features = X.shape[1]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=100, batch_size=32, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE4qgQGhqERI",
        "outputId": "6c9ecedf-d1c2-45e1-b620-a4eed107eadd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bb7884ccdc0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accelerate Training with Batch Normalization**"
      ],
      "metadata": {
        "id": "60rLt4nTqYdr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYiJ5qDnp6Nf",
        "outputId": "904283f7-e336-4f11-b556-c64b4cca74a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bb778401ba0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# example of using batch normalization\n",
        "from sklearn.datasets import make_classification\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from matplotlib import pyplot\n",
        "# create the dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
        "# determine the number of input features\n",
        "n_features = X.shape[1]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=100, batch_size=32, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Early Stopping**"
      ],
      "metadata": {
        "id": "RtJNUzeYtiS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of using early stopping\n",
        "from sklearn.datasets import make_classification\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# create the dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
        "# determine the number of input features\n",
        "n_features = X.shape[1]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "# configure early stopping\n",
        "es = EarlyStopping(monitor='val_loss', patience=5)\n",
        "# fit the model\n",
        "history = model.fit(X, y, epochs=200, batch_size=32, verbose=0, validation_split=0.3, callbacks=[es])"
      ],
      "metadata": {
        "id": "bOT30RAdteSX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}